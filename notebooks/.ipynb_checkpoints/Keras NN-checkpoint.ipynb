{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import scipy.io as sio\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "\n",
    "# import required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, TimeDistributed, Dropout, RepeatVector, LSTM, concatenate, Embedding, Input, BatchNormalization\n",
    "from keras.layers.core import Activation\n",
    "from keras import metrics\n",
    "import pickle\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_list = ['Dea', 'Greta', 'Jeppe', 'Nicolai', 'Paolo']\n",
    "#source_list = ['Dea']\n",
    "\n",
    "X_train_temp = []\n",
    "classes = []\n",
    "count_sources = 0\n",
    "for ii in source_list:\n",
    "\n",
    "    #data = sio.loadmat('C:/Users/nicol/Desktop/Dea/EEG/EEG_sources_vieworder_' + ii)\n",
    "    data = sio.loadmat('C:/Users/nicol/Desktop/Dea/EEG/eeg_events_' + ii)\n",
    "    if count_sources == 0:\n",
    "        #eeg = data['EEG_sources'].transpose()\n",
    "        #X_train_temp = np.array(eeg.todense())\n",
    "        eeg = data['eeg_events'].transpose()\n",
    "        X_train_temp = eeg.reshape(eeg.shape[0],eeg.shape[2]*eeg.shape[1])\n",
    "        count_sources += 1\n",
    "    \n",
    "    elif count_sources > 0:\n",
    "        #eeg = data['EEG_sources'].transpose()\n",
    "        #eeg = eeg[:,eeg.getnnz(0)>0]\n",
    "        #data = sio.loadmat('C:/Users/nicol/Desktop/Dea/EEG/image_semantics_' + ii)\n",
    "        eeg = data['eeg_events'].transpose()\n",
    "        eeg = eeg.reshape(eeg.shape[0],eeg.shape[2]*eeg.shape[1])\n",
    "        X_train_temp = np.vstack((X_train_temp,eeg))\n",
    "    \n",
    "    count_images = 0\n",
    "    with open('image_order_' + ii + '.txt', 'rb') as f:\n",
    "        for jj in f:\n",
    "            if count_images > 0:\n",
    "                classes.append(jj)\n",
    "            count_images += 1\n",
    "\n",
    "b = range(20,690*len(source_list),30)\n",
    "y = pd.get_dummies(classes)\n",
    "y_classes = list(y.columns.values)\n",
    "y_train = np.array(y)\n",
    "y_test = y_train[b,:]\n",
    "y_train = np.delete(y_train,b,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3335, 17600)\n",
      "(3335, 23)\n",
      "(115, 17600)\n",
      "(115, 23)\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "xScale = StandardScaler().fit(X_train_temp)\n",
    "X_train = xScale.transform(X_train_temp)\n",
    "X_test = X_train[b,:]\n",
    "X_train = np.delete(X_train,b,0)\n",
    "# Printing shape of data\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(200, activation='relu', name='first_dense', kernel_initializer='he_normal', input_shape=(X_train.shape[1],)))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(100, activation='relu', name='second_dense', kernel_initializer='he_normal'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(y_train.shape[1], activation='relu', name='third_dense', kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Activation('softmax', name='Softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3335 samples, validate on 115 samples\n",
      "Epoch 1/20\n",
      "3335/3335 [==============================] - 2s 501us/step - loss: 3.4358 - acc: 0.0417 - val_loss: 3.4394 - val_acc: 0.0348\n",
      "Epoch 2/20\n",
      "3335/3335 [==============================] - 1s 275us/step - loss: 2.9105 - acc: 0.2000 - val_loss: 3.3718 - val_acc: 0.0522\n",
      "Epoch 3/20\n",
      "3335/3335 [==============================] - 1s 286us/step - loss: 2.5649 - acc: 0.3316 - val_loss: 3.3458 - val_acc: 0.0348\n",
      "Epoch 4/20\n",
      "3335/3335 [==============================] - 1s 290us/step - loss: 2.2640 - acc: 0.4528 - val_loss: 3.2757 - val_acc: 0.0609\n",
      "Epoch 5/20\n",
      "3335/3335 [==============================] - 1s 294us/step - loss: 1.9895 - acc: 0.5673 - val_loss: 3.3058 - val_acc: 0.0609\n",
      "Epoch 6/20\n",
      "3335/3335 [==============================] - 1s 295us/step - loss: 1.8459 - acc: 0.6153 - val_loss: 3.3073 - val_acc: 0.0870\n",
      "Epoch 7/20\n",
      "3335/3335 [==============================] - 1s 291us/step - loss: 1.6687 - acc: 0.6663 - val_loss: 3.3385 - val_acc: 0.0609\n",
      "Epoch 8/20\n",
      "3335/3335 [==============================] - 1s 275us/step - loss: 1.5343 - acc: 0.7103 - val_loss: 3.3429 - val_acc: 0.0435\n",
      "Epoch 9/20\n",
      "3335/3335 [==============================] - 1s 279us/step - loss: 1.4419 - acc: 0.7397 - val_loss: 3.3070 - val_acc: 0.0522\n",
      "Epoch 10/20\n",
      "3335/3335 [==============================] - 1s 281us/step - loss: 1.3289 - acc: 0.7664 - val_loss: 3.3622 - val_acc: 0.0957\n",
      "Epoch 11/20\n",
      "3335/3335 [==============================] - 1s 289us/step - loss: 1.2224 - acc: 0.7919 - val_loss: 3.4297 - val_acc: 0.0609\n",
      "Epoch 12/20\n",
      "3335/3335 [==============================] - 1s 291us/step - loss: 1.1491 - acc: 0.8057 - val_loss: 3.3474 - val_acc: 0.0609\n",
      "Epoch 13/20\n",
      "3335/3335 [==============================] - 1s 325us/step - loss: 1.0459 - acc: 0.8258 - val_loss: 3.7494 - val_acc: 0.0348\n",
      "Epoch 14/20\n",
      "3335/3335 [==============================] - 1s 305us/step - loss: 1.0368 - acc: 0.8243 - val_loss: 3.3875 - val_acc: 0.0696\n",
      "Epoch 15/20\n",
      "3335/3335 [==============================] - 1s 286us/step - loss: 0.9771 - acc: 0.8429 - val_loss: 3.4125 - val_acc: 0.0957\n",
      "Epoch 16/20\n",
      "3335/3335 [==============================] - 1s 293us/step - loss: 0.9273 - acc: 0.8555 - val_loss: 3.3633 - val_acc: 0.0609\n",
      "Epoch 17/20\n",
      "3335/3335 [==============================] - 1s 286us/step - loss: 0.8384 - acc: 0.8660 - val_loss: 3.4429 - val_acc: 0.0522\n",
      "Epoch 18/20\n",
      "3335/3335 [==============================] - 1s 279us/step - loss: 0.7977 - acc: 0.8702 - val_loss: 3.3961 - val_acc: 0.0783\n",
      "Epoch 19/20\n",
      "3335/3335 [==============================] - 1s 295us/step - loss: 0.7807 - acc: 0.8741 - val_loss: 3.3961 - val_acc: 0.0696\n",
      "Epoch 20/20\n",
      "3335/3335 [==============================] - 1s 291us/step - loss: 0.7226 - acc: 0.8849 - val_loss: 3.4548 - val_acc: 0.0696\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, shuffle=True, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testPredict = model.predict(X_test)\n",
    "predict_classes = testPredict.argmax(1)\n",
    "true_classes = y_test.argmax(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0 1 0 1 1 0 0 0 0 0 1 0 2 0 0 0 1 0 0 0 0]\n",
      "0.0869565217391\n"
     ]
    }
   ],
   "source": [
    "#print(true_classes)\n",
    "#print(predict_classes)\n",
    "\n",
    "hej = np.array(predict_classes-true_classes == 0)\n",
    "hej = sum(hej.reshape(5, 23),0)\n",
    "print(hej)\n",
    "print(sum(hej)/115)\n",
    "#len(predict_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = metrics.top_k_categorical_accuracy(y_test,testPredict,k=1)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "v = sess.run(predictions)    \n",
    "print(v) # will show you your variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first_dense (Dense)          (None, 200)               3520200   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "second_dense (Dense)         (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "third_dense (Dense)          (None, 23)                2323      \n",
      "_________________________________________________________________\n",
      "Softmax (Activation)         (None, 23)                0         \n",
      "=================================================================\n",
      "Total params: 3,543,823\n",
      "Trainable params: 3,543,223\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
