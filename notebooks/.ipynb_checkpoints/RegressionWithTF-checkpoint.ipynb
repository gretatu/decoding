{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import scipy.io as sio\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "\n",
    "# import required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from tensorflow.python.framework import ops\n",
    "import scipy\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = sio.loadmat('C:/Users/nicol/Desktop/Dea/EEG/EEG_sources_vieworder_Dea.mat')\n",
    "data = sio.loadmat('C:/Users/nicol/Desktop/Dea/EEG/EEG_sources_vieworder_Jeppe.mat')\n",
    "eeg = data['EEG_sources']\n",
    "data = sio.loadmat('C:/Users/nicol/Desktop/Dea/EEG/image_semantics_Dea')\n",
    "image_sem = data['image_semantics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240900, 690)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690, 240900, 5)\n",
      "(690, 2048, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "# Image semantics\n",
    "# EEG_events \n",
    "\n",
    "source_list = ['Dea', 'Greta', 'Jeppe', 'Nicolai', 'Paolo']\n",
    "\n",
    "X_train_temp = []\n",
    "y_train_temp = []\n",
    "for ii in source_list:\n",
    "\n",
    "    data = sio.loadmat('C:/Users/nicol/Desktop/Dea/EEG/EEG_sources_vieworder_' + ii)\n",
    "    eeg = data['EEG_sources']\n",
    "    data = sio.loadmat('C:/Users/nicol/Desktop/Dea/EEG/image_semantics_' + ii)\n",
    "    image_sem = data['image_semantics']\n",
    "    eeg = eeg.todense()\n",
    "    \n",
    "    # Transposing data    \n",
    "    X_train_temp.append(eeg)\n",
    "    y_train_temp.append(image_sem)\n",
    "    \n",
    "\n",
    "X_train_temp = np.transpose(X_train_temp)\n",
    "#X_train_temp = X_train_temp.reshape(690,X_train_temp.shape[2])\n",
    "y_train_temp = np.transpose(y_train_temp)\n",
    "# Printing shape of data\n",
    "print(X_train_temp.shape)\n",
    "print(y_train_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3450, 240900)\n",
      "(3450, 2048)\n"
     ]
    }
   ],
   "source": [
    "X_train_temp = X_train_temp.reshape(690*len(source_list),X_train_temp.shape[1])\n",
    "y_train_temp = y_train_temp.reshape(690*len(source_list),y_train_temp.shape[1])\n",
    "print(X_train_temp.shape)\n",
    "print(y_train_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "xScale = StandardScaler().fit(X_train_temp)\n",
    "X_train = xScale.transform(X_train_temp)\n",
    "yScale = StandardScaler().fit(y_train_temp)\n",
    "y_train = yScale.transform(y_train_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "xScale = StandardScaler().fit(X_train_temp)\n",
    "X_train = xScale.transform(X_train_temp)\n",
    "X_test = xScale.transform(X_test_temp)\n",
    "yScale = StandardScaler().fit(y_train_temp)\n",
    "y_train = yScale.transform(y_train_temp)\n",
    "y_test = yScale.transform(y_test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify 'Ridge' or 'LASSO'\n",
    "regression_type = 'Elastic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clear out old graph\n",
    "ops.reset_default_graph()\n",
    "\n",
    "# Create graph\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare batch size\n",
    "batch_size = 256\n",
    "\n",
    "# Initialize placeholders\n",
    "x_data = tf.placeholder(shape=[None, X_train.shape[1]], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, y_train.shape[1]], dtype=tf.float32)\n",
    "\n",
    "# make results reproducible\n",
    "seed = 13\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# Create variables for linear regression\n",
    "A = tf.Variable(tf.random_normal(shape=[X_train.shape[1],1]))\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "\n",
    "# Declare model operations\n",
    "model_output = tf.add(b,tf.matmul(x_data, A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select appropriate loss function based on regression type\n",
    "\n",
    "if regression_type == 'LASSO':\n",
    "    # Declare Lasso loss function\n",
    "    # Lasso Loss = L2_Loss + heavyside_step,\n",
    "    # Where heavyside_step ~ 0 if A < constant, otherwise ~ 99\n",
    "    lasso_param = tf.constant(0.9)\n",
    "    heavyside_step = tf.truediv(1., tf.add(1., tf.exp(tf.multiply(-50., tf.subtract(A, lasso_param)))))\n",
    "    regularization_param = tf.multiply(heavyside_step, 99.)\n",
    "    loss = tf.expand_dims(tf.add(tf.reduce_mean(tf.square(y_target - model_output)), regularization_param),0)\n",
    "\n",
    "elif regression_type == 'Ridge':\n",
    "    # Declare the Ridge loss function\n",
    "    # Ridge loss = L2_loss + L2 norm of slope\n",
    "    ridge_param = tf.constant(1.)\n",
    "    ridge_loss = tf.reduce_mean(tf.square(A))\n",
    "    loss = tf.expand_dims(tf.add(tf.reduce_mean(tf.square(y_target - model_output)), tf.multiply(ridge_param, ridge_loss)), 0)\n",
    "    \n",
    "elif regression_type == 'Elastic':\n",
    "    # Declare the elastic net loss function\n",
    "    elastic_param1 = tf.constant(1.)\n",
    "    elastic_param2 = tf.constant(1.)\n",
    "    l1_a_loss = tf.reduce_mean(tf.abs(A))\n",
    "    l2_a_loss = tf.reduce_mean(tf.square(A))\n",
    "    e1_term = tf.multiply(elastic_param1, l1_a_loss)\n",
    "    e2_term = tf.multiply(elastic_param2, l2_a_loss)\n",
    "    #loss = tf.expand_dims(tf.add(tf.add(tf.reduce_mean(tf.square(y_target - model_output)), elastic_param1), elastic_param2), 0)\n",
    "    loss = tf.expand_dims(tf.add(tf.add(tf.reduce_mean(tf.square(y_target - model_output)), e1_term), e2_term), 0)\n",
    "\n",
    "else:\n",
    "    print('Invalid regression_type parameter value',file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.00001)\n",
    "train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #2 A = [[-0.50547552]\n",
      " [-2.48206425]\n",
      " [-0.41441989]\n",
      " ..., \n",
      " [-0.24002972]\n",
      " [ 0.09253517]\n",
      " [ 0.03704094]] b = [[-0.84819561]]\n",
      "Loss = [ 112830.828125]\n",
      "\n",
      "\n",
      "Step #4 A = [[-0.50601578]\n",
      " [-2.48249745]\n",
      " [-0.41407365]\n",
      " ..., \n",
      " [-0.24119079]\n",
      " [ 0.09243419]\n",
      " [ 0.03616804]] b = [[-0.84927517]]\n",
      "Loss = [ 122335.65625]\n",
      "\n",
      "\n",
      "Step #6 A = [[-0.50610596]\n",
      " [-2.48219848]\n",
      " [-0.41400969]\n",
      " ..., \n",
      " [-0.24223958]\n",
      " [ 0.09272805]\n",
      " [ 0.03552406]] b = [[-0.84883881]]\n",
      "Loss = [ 145505.734375]\n",
      "\n",
      "\n",
      "Step #8 A = [[-0.50509107]\n",
      " [-2.48256278]\n",
      " [-0.41388363]\n",
      " ..., \n",
      " [-0.24216282]\n",
      " [ 0.09350055]\n",
      " [ 0.03537845]] b = [[-0.84879571]]\n",
      "Loss = [ 129857.7734375]\n",
      "\n",
      "\n",
      "Step #10 A = [[-0.50535351]\n",
      " [-2.48318338]\n",
      " [-0.41417411]\n",
      " ..., \n",
      " [-0.24305288]\n",
      " [ 0.09351759]\n",
      " [ 0.03637198]] b = [[-0.8488754]]\n",
      "Loss = [ 103984.7890625]\n",
      "\n",
      "\n",
      "Step #12 A = [[-0.50308698]\n",
      " [-2.48649526]\n",
      " [-0.41472819]\n",
      " ..., \n",
      " [-0.24293758]\n",
      " [ 0.09427179]\n",
      " [ 0.03732882]] b = [[-0.84963191]]\n",
      "Loss = [ 168904.734375]\n",
      "\n",
      "\n",
      "Step #14 A = [[-0.50293237]\n",
      " [-2.48613524]\n",
      " [-0.41370219]\n",
      " ..., \n",
      " [-0.2428484 ]\n",
      " [ 0.09411068]\n",
      " [ 0.03764696]] b = [[-0.85011488]]\n",
      "Loss = [ 137783.296875]\n",
      "\n",
      "\n",
      "Step #16 A = [[-0.5031687 ]\n",
      " [-2.4861865 ]\n",
      " [-0.41279075]\n",
      " ..., \n",
      " [-0.24289882]\n",
      " [ 0.09417414]\n",
      " [ 0.03813704]] b = [[-0.8505224]]\n",
      "Loss = [ 158784.515625]\n",
      "\n",
      "\n",
      "Step #18 A = [[-0.50252789]\n",
      " [-2.48620868]\n",
      " [-0.4128831 ]\n",
      " ..., \n",
      " [-0.24290499]\n",
      " [ 0.09525143]\n",
      " [ 0.03890665]] b = [[-0.85028756]]\n",
      "Loss = [ 130046.0390625]\n",
      "\n",
      "\n",
      "Step #20 A = [[-0.5020805 ]\n",
      " [-2.4856956 ]\n",
      " [-0.41374469]\n",
      " ..., \n",
      " [-0.24291006]\n",
      " [ 0.09577172]\n",
      " [ 0.03940987]] b = [[-0.84980071]]\n",
      "Loss = [ 121479.9765625]\n",
      "\n",
      "\n",
      "Step #22 A = [[-0.50070167]\n",
      " [-2.48512578]\n",
      " [-0.41371846]\n",
      " ..., \n",
      " [-0.24338137]\n",
      " [ 0.09574009]\n",
      " [ 0.03883411]] b = [[-0.84865993]]\n",
      "Loss = [ 104846.40625]\n",
      "\n",
      "\n",
      "Step #24 A = [[-0.50045753]\n",
      " [-2.48600006]\n",
      " [-0.41373262]\n",
      " ..., \n",
      " [-0.244574  ]\n",
      " [ 0.09528352]\n",
      " [ 0.03871859]] b = [[-0.8484723]]\n",
      "Loss = [ 89568.4609375]\n",
      "\n",
      "\n",
      "Step #26 A = [[-0.50114477]\n",
      " [-2.48579359]\n",
      " [-0.41336563]\n",
      " ..., \n",
      " [-0.24545665]\n",
      " [ 0.09578958]\n",
      " [ 0.03866966]] b = [[-0.84854734]]\n",
      "Loss = [ 104449.2734375]\n",
      "\n",
      "\n",
      "Step #28 A = [[-0.50181168]\n",
      " [-2.48914075]\n",
      " [-0.41304401]\n",
      " ..., \n",
      " [-0.24611431]\n",
      " [ 0.09601852]\n",
      " [ 0.03957087]] b = [[-0.84709054]]\n",
      "Loss = [ 133610.015625]\n",
      "\n",
      "\n",
      "Step #30 A = [[-0.50095403]\n",
      " [-2.48812437]\n",
      " [-0.41324598]\n",
      " ..., \n",
      " [-0.24614061]\n",
      " [ 0.09655342]\n",
      " [ 0.03903052]] b = [[-0.84872681]]\n",
      "Loss = [ 115225.578125]\n",
      "\n",
      "\n",
      "Step #32 A = [[-0.50027966]\n",
      " [-2.48838091]\n",
      " [-0.41298476]\n",
      " ..., \n",
      " [-0.24609759]\n",
      " [ 0.09548683]\n",
      " [ 0.03836862]] b = [[-0.84751105]]\n",
      "Loss = [ 122414.7265625]\n",
      "\n",
      "\n",
      "Step #34 A = [[-0.49972251]\n",
      " [-2.48980689]\n",
      " [-0.41309893]\n",
      " ..., \n",
      " [-0.2452991 ]\n",
      " [ 0.09477329]\n",
      " [ 0.03824743]] b = [[-0.8481037]]\n",
      "Loss = [ 123248.0078125]\n",
      "\n",
      "\n",
      "Step #36 A = [[-0.4978134 ]\n",
      " [-2.49097395]\n",
      " [-0.41321367]\n",
      " ..., \n",
      " [-0.24535048]\n",
      " [ 0.09502816]\n",
      " [ 0.03914807]] b = [[-0.8489458]]\n",
      "Loss = [ 99388.6640625]\n",
      "\n",
      "\n",
      "Step #38 A = [[-0.49770218]\n",
      " [-2.49153614]\n",
      " [-0.41282475]\n",
      " ..., \n",
      " [-0.24508539]\n",
      " [ 0.09492591]\n",
      " [ 0.04028493]] b = [[-0.84988266]]\n",
      "Loss = [ 109021.71875]\n",
      "\n",
      "\n",
      "Step #40 A = [[-0.49720463]\n",
      " [-2.49228954]\n",
      " [-0.41320875]\n",
      " ..., \n",
      " [-0.24503545]\n",
      " [ 0.09537844]\n",
      " [ 0.03999891]] b = [[-0.8503741]]\n",
      "Loss = [ 102336.90625]\n",
      "\n",
      "\n",
      "Step #42 A = [[-0.49654084]\n",
      " [-2.49247551]\n",
      " [-0.41337359]\n",
      " ..., \n",
      " [-0.24500872]\n",
      " [ 0.09474947]\n",
      " [ 0.04029185]] b = [[-0.84966189]]\n",
      "Loss = [ 91642.96875]\n",
      "\n",
      "\n",
      "Step #44 A = [[-0.49502602]\n",
      " [-2.49163079]\n",
      " [-0.41360199]\n",
      " ..., \n",
      " [-0.24462576]\n",
      " [ 0.09514284]\n",
      " [ 0.04088734]] b = [[-0.85033476]]\n",
      "Loss = [ 103726.2578125]\n",
      "\n",
      "\n",
      "Step #46 A = [[-0.49398994]\n",
      " [-2.49130988]\n",
      " [-0.41385344]\n",
      " ..., \n",
      " [-0.24461313]\n",
      " [ 0.09428144]\n",
      " [ 0.04146902]] b = [[-0.8509317]]\n",
      "Loss = [ 107372.0390625]\n",
      "\n",
      "\n",
      "Step #48 A = [[-0.4926326 ]\n",
      " [-2.49056959]\n",
      " [-0.41358131]\n",
      " ..., \n",
      " [-0.2444668 ]\n",
      " [ 0.09529691]\n",
      " [ 0.04188782]] b = [[-0.85117155]]\n",
      "Loss = [ 86700.109375]\n",
      "\n",
      "\n",
      "Step #50 A = [[-0.49250278]\n",
      " [-2.49181652]\n",
      " [-0.41425017]\n",
      " ..., \n",
      " [-0.24447446]\n",
      " [ 0.0972033 ]\n",
      " [ 0.04113585]] b = [[-0.85029513]]\n",
      "Loss = [ 130123.3203125]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Training loop\n",
    "loss_vec = []\n",
    "for i in range(50):\n",
    "    rand_index = np.random.choice(len(X_train), size=batch_size)\n",
    "    rand_x = X_train[rand_index]\n",
    "    rand_y = y_train[rand_index]\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    loss_vec.append(temp_loss[0])\n",
    "    if (i+1)%2==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)) + ' b = ' + str(sess.run(b)))\n",
    "        print('Loss = ' + str(temp_loss))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 17600)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Add_14:0' shape=(17600, 1) dtype=float32>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.add(b,tf.matmul(x_data, A))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
